{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00d0f14",
   "metadata": {},
   "source": [
    "## Set up dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab8ac473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/SOFO/TranslationalEquivariance/SideChainTransformer/scripts`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/SOFO/TranslationalEquivariance/SideChainTransformer/scripts/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/SOFO/TranslationalEquivariance/SideChainTransformer/scripts/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "Pkg.add([\"ProteinChains\", \"BSON\", \"Flux\", \"ConcreteStructs\", \"ChainRulesCore\", \"Einops\", \"RandomFeatureMaps\", \"Onion\"])\n",
    "\n",
    "using ProteinChains, BSON, Flux, ConcreteStructs, ChainRulesCore, Einops, RandomFeatureMaps\n",
    "using Flux: onehotbatch, mse, AdamW\n",
    "includet(\"../src/naive.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdefbba",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "481ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATOMNAMES = String[\"C\", \"CA\", \"CB\", \"CD\", \"CD1\", \"CD2\", \"CE\", \"CE1\", \"CE2\", \"CE3\", \"CG\", \"CG1\", \"CG2\", \"CH2\", \"CZ\", \"CZ2\", \"CZ3\", \"H\", \"H1\", \"H2\", \"H3\", \"HA\", \"HA2\", \"HA3\", \"HB\", \"HB1\", \"HB2\", \"HB3\", \"HD1\", \"HD11\", \"HD12\", \"HD13\", \"HD2\", \"HD21\", \"HD22\", \"HD23\", \"HD3\", \"HE\", \"HE1\", \"HE2\", \"HE21\", \"HE22\", \"HE3\", \"HG\", \"HG1\", \"HG11\", \"HG12\", \"HG13\", \"HG2\", \"HG21\", \"HG22\", \"HG23\", \"HG3\", \"HH\", \"HH11\", \"HH12\", \"HH2\", \"HH21\", \"HH22\", \"HZ\", \"HZ1\", \"HZ2\", \"HZ3\", \"N\", \"ND1\", \"ND2\", \"NE\", \"NE1\", \"NE2\", \"NH1\", \"NH2\", \"NZ\", \"O\", \"OD1\", \"OD2\", \"OE1\", \"OE2\", \"OG\", \"OG1\", \"OH\", \"OXT\", \"SD\", \"SG\"]\n",
    "AA_TO_ATOMS = Dict(\"Q\" => [\"C\", \"CA\", \"CB\", \"CD\", \"CG\", \"N\", \"NE2\", \"O\", \"OE1\"], \"W\" => [\"C\", \"CA\", \"CB\", \"CD1\", \"CD2\", \"CE2\", \"CE3\", \"CG\", \"CH2\", \"CZ2\", \"CZ3\", \"N\", \"NE1\", \"O\"], \"T\" => [\"C\", \"CA\", \"CB\", \"CG2\", \"N\", \"O\", \"OG1\"], \"P\" => [\"C\", \"CA\", \"CB\", \"CD\", \"CG\", \"N\", \"O\"], \"C\" => [\"C\", \"CA\", \"CB\", \"N\", \"O\", \"SG\"], \"V\" => [\"C\", \"CA\", \"CB\", \"CG1\", \"CG2\", \"N\", \"O\"], \"L\" => [\"C\", \"CA\", \"CB\", \"CD1\", \"CD2\", \"CG\", \"N\", \"O\"], \"M\" => [\"C\", \"CA\", \"CB\", \"CE\", \"CG\", \"N\", \"O\", \"SD\"], \"N\" => [\"C\", \"CA\", \"CB\", \"CG\", \"N\", \"ND2\", \"O\", \"OD1\"], \"H\" => [\"C\", \"CA\", \"CB\", \"CD2\", \"CE1\", \"CG\", \"N\", \"ND1\", \"NE2\", \"O\"], \"A\" => [\"C\", \"CA\", \"CB\", \"N\", \"O\"], \"X\" => [\"C\", \"CA\", \"CB\", \"N\", \"O\"], \"D\" => [\"C\", \"CA\", \"CB\", \"CG\", \"N\", \"O\", \"OD1\", \"OD2\"], \"G\" => [\"C\", \"CA\", \"N\", \"O\"], \"E\" => [\"C\", \"CA\", \"CB\", \"CD\", \"CG\", \"N\", \"O\", \"OE1\", \"OE2\"], \"Y\" => [\"C\", \"CA\", \"CB\", \"CD1\", \"CD2\", \"CE1\", \"CE2\", \"CG\", \"CZ\", \"N\", \"O\", \"OH\"], \"I\" => [\"C\", \"CA\", \"CB\", \"CD1\", \"CG1\", \"CG2\", \"N\", \"O\"], \"S\" => [\"C\", \"CA\", \"CB\", \"N\", \"O\", \"OG\"], \"K\" => [\"C\", \"CA\", \"CB\", \"CD\", \"CE\", \"CG\", \"N\", \"NZ\", \"O\"], \"R\" => [\"C\", \"CA\", \"CB\", \"CD\", \"CG\", \"CZ\", \"N\", \"NE\", \"NH1\", \"NH2\", \"O\"], \"F\" => [\"C\", \"CA\", \"CB\", \"CD1\", \"CD2\", \"CE1\", \"CE2\", \"CG\", \"CZ\", \"N\", \"O\"])\n",
    "\n",
    "BSON.@load \"../data/pdb500_allatom.bson\" allatom_dataset;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bad6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:chainids, :AAs, :backbone_xyz, :atom_xyz, :atom_res, :atom_name)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allatom_dataset[1] |> propertynames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e145c9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prep_data (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calc_dist(p1, p2) = Float32(sqrt(sum((p1 .- p2).^2)))\n",
    "\n",
    "function prep_data(protein)\n",
    "    maskcalpha = protein.atom_name .== \"CA\"\n",
    "\n",
    "    atom_xyz = Float32.(protein.atom_xyz[:, maskcalpha])\n",
    "    atom_res = protein.atom_res[maskcalpha]\n",
    "\n",
    "    atom_name = Float32.(onehotbatch(protein.atom_name[maskcalpha], ATOMNAMES))\n",
    "    AAs_res = Float32.(onehotbatch(protein.AAs, ProteinChains.AMINOACIDS))\n",
    "    AAs_atom = Float32.(onehotbatch(protein.AAs[atom_res], ProteinChains.AMINOACIDS))\n",
    "    \n",
    "    backbone_xyz = Float32.(protein.backbone_xyz[:, 2, :])\n",
    "\n",
    "    backbone_distanceincrement = map(calc_dist, eachcol(backbone_xyz[:, 2:end]), eachcol(backbone_xyz[:, 1:end-1]))\n",
    "    backbone_distanceincrement = [backbone_distanceincrement; zero(Float32)]\n",
    "    backbone_distanceincrement = reshape(backbone_distanceincrement, 1, size(backbone_distanceincrement)...)\n",
    "\n",
    "    atom_calpha_distance = map(calc_dist, eachcol(atom_xyz), eachcol(backbone_xyz[:, atom_res]))\n",
    "    atom_calpha_distance = reshape(atom_calpha_distance, 1, size(atom_calpha_distance)...)\n",
    "\n",
    "    return (; AAs_res, AAs_atom, backbone_distanceincrement, atom_calpha_distance, atom_xyz, backbone_xyz, atom_name)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602cf629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prep_batch (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function prep_batch(data)\n",
    "    data = map(prep_data, data)\n",
    "    \n",
    "    AAs_res = Flux.batch(map(x -> x.AAs_res, data))\n",
    "    AAs_atom = Flux.batch(map(x -> x.AAs_atom, data))\n",
    "    backbone_distanceincrement = Flux.batch(map(x -> x.backbone_distanceincrement, data))\n",
    "    atom_calpha_distance = Flux.batch(map(x -> x.atom_calpha_distance, data))\n",
    "    atom_xyz = Flux.batch(map(x -> x.atom_xyz, data))\n",
    "    backbone_xyz = Flux.batch(map(x -> x.backbone_xyz, data))\n",
    "    atom_name = Flux.batch(map(x -> x.atom_name, data))\n",
    " \n",
    "    return (; AAs_res, AAs_atom, backbone_distanceincrement, atom_calpha_distance, atom_xyz, backbone_xyz, atom_name) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f79287b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chop_proteins (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function chop_proteins(proteins, max_back = 100)\n",
    "    chopped_proteins = []\n",
    "\n",
    "    for protein in proteins\n",
    "        back_len = length(protein.AAs)\n",
    "        if back_len < max_back\n",
    "            push!(chopped_proteins, protein)\n",
    "        else\n",
    "            for start in 1:max_back:back_len\n",
    "                stop = start + max_back - 1\n",
    "                stop <= back_len || break\n",
    "\n",
    "                atom_mask = findall(x -> start <= x <= stop, protein.atom_res)\n",
    "\n",
    "                # (:chainids, :AAs, :backbone_xyz, :atom_xyz, :atom_res, :atom_name)\n",
    "                chopped_prot = (; \n",
    "                    chainids = protein.chainids[start:stop],\n",
    "                    AAs = protein.AAs[start:stop],\n",
    "                    backbone_xyz = protein.backbone_xyz[:, start:stop],\n",
    "                    atom_xyz = protein.atom_xyz[:, atom_mask],\n",
    "                    atom_res = protein.atom_res[atom_mask],\n",
    "                    atom_name = protein.atom_name[atom_mask]\n",
    "                )\n",
    "                push!(chopped_proteins, chopped_prot)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return chopped_proteins\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c3d9e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `onehotbatch` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing OneHotArrays in the current active module Main",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `onehotbatch` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Hint: a global variable of this name may be made accessible by importing OneHotArrays in the current active module Main\n",
      "\n",
      "Stacktrace:\n",
      " [1] prep_data(protein::@NamedTuple{chainids::Vector{Any}, AAs::Vector{Any}, backbone_xyz::Array{Float64, 3}, atom_xyz::Matrix{Float32}, atom_res::Vector{Int64}, atom_name::Vector{String}})\n",
      "   @ Main ~/Desktop/SOFO/TranslationalEquivariance/SideChainTransformer/scripts/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:9\n",
      " [2] top-level scope\n",
      "   @ ~/Desktop/SOFO/TranslationalEquivariance/SideChainTransformer/scripts/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X11sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "prep_data(allatom_dataset[1]);\n",
    "prep_batch(allatom_dataset[1:1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799e4f5c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2aea130",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct AllAtomModel{L}\n",
    "    layers::L\n",
    "end\n",
    "\n",
    "Flux.@layer AllAtomModel\n",
    "\n",
    "function AllAtomModel(embed_dim, num_layers, num_heads)\n",
    "    layers = (;\n",
    "        # Layers for both\n",
    "        AA_encoder = Dense(21 => embed_dim),\n",
    "        cross_attention_layers = [Attention(embed_dim, num_heads) for _ in 1:num_layers],\n",
    "\n",
    "        # Layers for atoms\n",
    "        atomname_encoder = Dense(length(ATOMNAMES) => embed_dim),\n",
    "        atom_calpha_distance_encoder = RandomFourierFeatures(1 => embed_dim, one(Float32)),\n",
    "        atom_transformers = [NaiveTransformerBlock(embed_dim, num_heads, 3) for _ in 1:num_layers],\n",
    "        output_layer = Dense(embed_dim => 3),\n",
    "\n",
    "        # Layers for backbone\n",
    "        #locdiff_rff = RandomFourierFeatures(3 => embed_dim),\n",
    "        backbone_distanceincrement_encoder = RandomFourierFeatures(1 => embed_dim, one(Float32)),\n",
    "        backbone_transformers = [NaiveTransformerBlock(embed_dim, num_heads, 3) for _ in 1:num_layers],\n",
    "    )\n",
    "    return AllAtomModel(layers)\n",
    "end\n",
    "\n",
    "function (m::AllAtomModel)(AAs_res, AAs_atom, backbone_distanceincrement, atom_calpha_distance, atom_xyz, backbone_xyz, atom_name)\n",
    "    l = m.layers\n",
    "\n",
    "    x_res = l.backbone_distanceincrement_encoder(backbone_distanceincrement) + l.AA_encoder(AAs_res)\n",
    "    x_atom = l.atom_calpha_distance_encoder(atom_calpha_distance) + l.AA_encoder(AAs_atom) + l.atomname_encoder(atom_name)\n",
    "\n",
    "    for i in 1:length(l.atom_transformers)\n",
    "        x_atom = l.atom_transformers[i](x_atom, atom_xyz)\n",
    "        x_res = l.backbone_transformers[i](x_res, backbone_xyz)\n",
    "        x_atom = l.cross_attention_layers[i](x_atom, x_res)\n",
    "    end\n",
    "\n",
    "    y_atom = l.output_layer(x_atom)\n",
    "\n",
    "    return y_atom\n",
    "end\n",
    "\n",
    "(m::AllAtomModel)(prepped_batch) = m(prepped_batch.AAs_res, prepped_batch.AAs_atom, prepped_batch.backbone_distanceincrement, prepped_batch.atom_calpha_distance, prepped_batch.atom_xyz, prepped_batch.backbone_xyz, prepped_batch.atom_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fbd41",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a344452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllAtomModel(\n",
       "  Dense(21 => 24),                      \u001b[90m# 528 parameters\u001b[39m\n",
       "  [\n",
       "    Attention(\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      24,\n",
       "      4,\n",
       "      4,\n",
       "      6,\n",
       "    ),\n",
       "    Attention(\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      Dense(24 => 24; bias=false),      \u001b[90m# 576 parameters\u001b[39m\n",
       "      24,\n",
       "      4,\n",
       "      4,\n",
       "      6,\n",
       "    ),\n",
       "  ],\n",
       "  Dense(83 => 24),                      \u001b[90m# 2_016 parameters\u001b[39m\n",
       "  RandomFourierFeatures{Float32, Matrix{Float32}}(Float32[-4.0496616 10.943888 … 10.990238 -1.3580636]),\n",
       "  [\n",
       "    NaiveTransformerBlock(\n",
       "      Attention(\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        24,\n",
       "        4,\n",
       "        4,\n",
       "        6,\n",
       "      ),\n",
       "      StarGLU(\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(96 => 24; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        NNlib.swish,\n",
       "      ),\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      NaiveRoPE(10000.0f0),\n",
       "    ),\n",
       "    NaiveTransformerBlock(\n",
       "      Attention(\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        24,\n",
       "        4,\n",
       "        4,\n",
       "        6,\n",
       "      ),\n",
       "      StarGLU(\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(96 => 24; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        NNlib.swish,\n",
       "      ),\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      NaiveRoPE(10000.0f0),\n",
       "    ),\n",
       "  ],\n",
       "  Dense(24 => 3),                       \u001b[90m# 75 parameters\u001b[39m\n",
       "  RandomFourierFeatures{Float32, Matrix{Float32}}(Float32[-0.56644386 -2.6911502 … 3.1843865 -2.5091846]),\n",
       "  [\n",
       "    NaiveTransformerBlock(\n",
       "      Attention(\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        24,\n",
       "        4,\n",
       "        4,\n",
       "        6,\n",
       "      ),\n",
       "      StarGLU(\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(96 => 24; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        NNlib.swish,\n",
       "      ),\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      NaiveRoPE(10000.0f0),\n",
       "    ),\n",
       "    NaiveTransformerBlock(\n",
       "      Attention(\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        Dense(24 => 24; bias=false),    \u001b[90m# 576 parameters\u001b[39m\n",
       "        24,\n",
       "        4,\n",
       "        4,\n",
       "        6,\n",
       "      ),\n",
       "      StarGLU(\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(96 => 24; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        Dense(24 => 96; bias=false),    \u001b[90m# 2_304 parameters\u001b[39m\n",
       "        NNlib.swish,\n",
       "      ),\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      RMSNorm{Float32, Vector{Float32}}(Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 1.0f-5),  \u001b[90m# 24 parameters\u001b[39m\n",
       "      NaiveRoPE(10000.0f0),\n",
       "    ),\n",
       "  ],\n",
       ") \u001b[90m        # Total: 50 trainable arrays, \u001b[39m44_283 parameters,\n",
       "\u001b[90m          # plus 2 non-trainable, 24 parameters, summarysize \u001b[39m176.535 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_dim = 8 * 3\n",
    "nheads = 4\n",
    "model = AllAtomModel(embed_dim, 2, nheads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a89b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = prep_batch(allatom_dataset[1:1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba3d46",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "\n",
    "- Training loop\n",
    "- Sampling code\n",
    "- Calpha distance rff for embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179e01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = Float32[]\n",
    " \n",
    "embed_dim = 8 * 3\n",
    "nheads = 4\n",
    "model = AllAtomModel(embed_dim, 2, nheads)\n",
    " \n",
    "opt_state = Flux.setup(AdamW(eta = 0.001), model)\n",
    " \n",
    "println(\"Starting training...\")\n",
    "for epoch in 1:1\n",
    "    tot_loss = 0f0\n",
    "    for i in 1:10\n",
    "        b = prep_batch(allatom_dataset[i:i])\n",
    "        l, g = Flux.withgradient(model) do m\n",
    "            y_pred = m(b)\n",
    " \n",
    "            y_true = b.atom_xyz\n",
    "            \n",
    "            loss = mse(y_pred, y_true)\n",
    "            return loss\n",
    "        end\n",
    "        \n",
    "        if !isnothing(g)\n",
    "            tot_loss += l\n",
    "            Flux.update!(opt_state, model, g[1])\n",
    "            push!(losses, l)\n",
    "        end\n",
    "        @info \"Epoch: $epoch; Loss: $(round(l, digits=4))\"\n",
    "    end\n",
    "    \n",
    "    avg_loss = tot_loss / 100\n",
    "    println(\"Epoch: $epoch; Average Loss: $(round(avg_loss, digits=4))\")\n",
    "end\n",
    "println(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
