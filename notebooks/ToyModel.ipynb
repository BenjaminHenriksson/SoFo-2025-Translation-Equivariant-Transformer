{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "#Pkg.add([\"Flux\", \"DLProteinFormats\", \"Onion\", \"RandomFeatureMaps\", \"StatsBase\", \"Plots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, DLProteinFormats, Onion, RandomFeatureMaps, StatsBase, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = DLProteinFormats.load(PDBSimpleFlat500);\n",
    "\n",
    "L = 30\n",
    "train_inds = findall(dat.len .> L)\n",
    " \n",
    "function random_batch(dat, L, B, filt_inds)\n",
    "    locs = zeros(Float32, 3, L, B)\n",
    "    inds = sample(filt_inds, B, replace=false)\n",
    "    AAs = zeros(Int, L, B)\n",
    "    for (i,ind) in enumerate(inds)\n",
    "        l_range = rand(1:dat[ind].len - L + 1)\n",
    "        locs[:, :, i] = dat[ind].locs[:, 1, l_range:l_range+L-1]\n",
    "        AAs[:, i] = dat[ind].AAs[l_range:l_range+L-1]\n",
    "    end\n",
    "    return (;locs, AAs = Flux.onehotbatch(AAs, 1:20))\n",
    "end\n",
    "\n",
    "batch = random_batch(dat, L, 10, train_inds);\n",
    " \n",
    "struct Toy0{L}\n",
    "    layers::L\n",
    "end\n",
    "Flux.@layer Toy0\n",
    "function Toy0()\n",
    "    layers = (;\n",
    "        AA_decoder = Dense(3 => 20, bias=false),\n",
    "    )\n",
    "    return Toy0(layers)\n",
    "end\n",
    "function (m::Toy0)(locs)\n",
    "    l = m.layers\n",
    "    aa_logits = l.AA_decoder(locs)\n",
    "    return aa_logits\n",
    "end\n",
    " \n",
    "struct Toy1{L}\n",
    "    layers::L\n",
    "end\n",
    "Flux.@layer Toy1\n",
    "function Toy1(dim, depth)\n",
    "    layers = (;\n",
    "        loc_encoder = Dense(3 => dim, bias=false),\n",
    "        transformers = [Onion.TransformerBlock(dim, 8, Onion.MultiDimRoPE(Int(dim/8), 3)) for _ in 1:depth],\n",
    "        AA_decoder = Dense(dim => 20, bias=false),\n",
    "    )\n",
    "    return Toy1(layers)\n",
    "end\n",
    "function (m::Toy1)(locs)\n",
    "    l = m.layers\n",
    "    x = l.loc_encoder(locs)\n",
    "    for transformerblock in l.transformers\n",
    "        x = transformerblock(x, 0, nothing, locs)\n",
    "        #locs = updatelocs(x, locs)\n",
    "    end\n",
    "    aa_logits = l.AA_decoder(x)\n",
    "    return aa_logits\n",
    "end\n",
    " \n",
    "struct Toy2{L}\n",
    "    layers::L\n",
    "end\n",
    "Flux.@layer Toy2\n",
    "function Toy2(dim, depth)\n",
    "    layers = (;\n",
    "        loc_rff = RandomFourierFeatures(3 => 64, 0.1f0),\n",
    "        loc_encoder = Dense(64 => dim, bias=false),\n",
    "        transformers = [Onion.TransformerBlock(dim, 8) for _ in 1:depth],\n",
    "        AA_decoder = Dense(dim => 20, bias=false),\n",
    "    )\n",
    "    return Toy2(layers)\n",
    "end\n",
    "function (m::Toy2)(locs)\n",
    "    l = m.layers\n",
    "    x = l.loc_encoder(l.loc_rff(locs))\n",
    "    for layer in l.transformers\n",
    "        x = layer(x, 0, nothing)\n",
    "    end\n",
    "    aa_logits = l.AA_decoder(x)\n",
    "    return aa_logits\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Toy0()\n",
    "model = Toy1(64, 4)\n",
    "#model = Toy2(64, 4)\n",
    "opt_state = Flux.setup(AdamW(eta = 0.001), model)\n",
    " \n",
    "losses = Float32[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1:20 # 1:100\n",
    "    tot_loss = 0f0\n",
    "    for i in 1:1_000 # 1:10_000\n",
    "        batch = random_batch(dat, L, 10, train_inds);\n",
    "        l, grad = Flux.withgradient(model) do m\n",
    "            aalogits = m(batch.locs)\n",
    "            Flux.logitcrossentropy(aalogits, batch.AAs)\n",
    "        end\n",
    "        Flux.update!(opt_state, model, grad[1])\n",
    "        tot_loss += l\n",
    "        if mod(i, 50) == 0\n",
    "            println(epoch, \" \", i, \" \", tot_loss/50)\n",
    "            push!(losses, tot_loss/50)\n",
    "            tot_loss = 0f0\n",
    "        end\n",
    "        (mod(i, 500) == 0) && savefig(plot(losses), \"losses_toy_MultiDimRoPE.pdf\")\n",
    "    end\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
