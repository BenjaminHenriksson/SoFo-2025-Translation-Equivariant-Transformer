{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "#Pkg.add([\"Flux\", \"DLProteinFormats\", \"Onion\", \"RandomFeatureMaps\", \"StatsBase\", \"Plots\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching pipe_writer(::VSCodeServer.IJuliaCore.IJuliaStdio{Base.PipeEndpoint, typeof(VSCodeServer.io_send_callback)})\nThe applicable method may be too new: running in world age 26711, while current world is 26750.\n\nClosest candidates are:\n  pipe_writer(::VSCodeServer.IJuliaCore.IJuliaStdio) (method too new to be called from this world context.)\n   @ VSCodeServer c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\IJuliaCore\\src\\stdio.jl:16\n  pipe_writer(!Matched::Base.ProcessChain)\n   @ Base process.jl:37\n  pipe_writer(!Matched::Pipe)\n   @ Base stream.jl:780\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching pipe_writer(::VSCodeServer.IJuliaCore.IJuliaStdio{Base.PipeEndpoint, typeof(VSCodeServer.io_send_callback)})\n",
      "The applicable method may be too new: running in world age 26711, while current world is 26750.\n",
      "\n",
      "Closest candidates are:\n",
      "  pipe_writer(::VSCodeServer.IJuliaCore.IJuliaStdio) (method too new to be called from this world context.)\n",
      "   @ VSCodeServer c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\IJuliaCore\\src\\stdio.jl:16\n",
      "  pipe_writer(!Matched::Base.ProcessChain)\n",
      "   @ Base process.jl:37\n",
      "  pipe_writer(!Matched::Pipe)\n",
      "   @ Base stream.jl:780\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      "  [1] unsafe_write(io::VSCodeServer.IJuliaCore.IJuliaStdio{Base.PipeEndpoint, typeof(VSCodeServer.io_send_callback)}, p::Ptr{UInt8}, nb::UInt64)\n",
      "    @ Base .\\io.jl:452\n",
      "  [2] unsafe_write(io::IOContext{IO}, p::Ptr{UInt8}, nb::UInt64)\n",
      "    @ Base .\\io.jl:452\n",
      "  [3] write\n",
      "    @ .\\strings\\io.jl:248 [inlined]\n",
      "  [4] print\n",
      "    @ .\\strings\\io.jl:250 [inlined]\n",
      "  [5] print(::IOContext{IO}, ::String, ::String, ::Vararg{String})\n",
      "    @ Base .\\strings\\io.jl:46\n",
      "  [6] println(::IOContext{IO}, ::String, ::Vararg{String})\n",
      "    @ Base .\\strings\\io.jl:75\n",
      "  [7] (::Base.Precompilation.var\"#40#80\"{String})()\n",
      "    @ Base.Precompilation .\\precompilation.jl:1052\n",
      "  [8] lock(f::Base.Precompilation.var\"#40#80\"{String}, l::ReentrantLock)\n",
      "    @ Base .\\lock.jl:232\n",
      "  [9] _precompilepkgs(pkgs::Vector{String}, internal_call::Bool, strict::Bool, warn_loaded::Bool, timing::Bool, _from_loading::Bool, configs::Vector{Pair{Cmd, Base.CacheFlags}}, io::IOContext{IO}, fancyprint::Bool, ignore_loaded::Bool)\n",
      "    @ Base.Precompilation .\\precompilation.jl:1051\n",
      " [10] precompilepkgs(pkgs::Vector{String}; internal_call::Bool, strict::Bool, warn_loaded::Bool, timing::Bool, _from_loading::Bool, configs::Pair{Cmd, Base.CacheFlags}, io::VSCodeServer.IJuliaCore.IJuliaStdio{Base.PipeEndpoint, typeof(VSCodeServer.io_send_callback)}, fancyprint::Bool, ignore_loaded::Bool)\n",
      "    @ Base.Precompilation .\\precompilation.jl:411\n",
      " [11] _require(pkg::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:2558\n",
      " [12] __require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:2388\n",
      " [13] #invoke_in_world#3\n",
      "    @ .\\essentials.jl:1089 [inlined]\n",
      " [14] invoke_in_world\n",
      "    @ .\\essentials.jl:1086 [inlined]\n",
      " [15] _require_prelocked(uuidkey::Base.PkgId, env::String)\n",
      "    @ Base .\\loading.jl:2375\n",
      " [16] macro expansion\n",
      "    @ .\\loading.jl:2314 [inlined]\n",
      " [17] macro expansion\n",
      "    @ .\\lock.jl:273 [inlined]\n",
      " [18] __require(into::Module, mod::Symbol)\n",
      "    @ Base .\\loading.jl:2271\n",
      " [19] #invoke_in_world#3\n",
      "    @ .\\essentials.jl:1089 [inlined]\n",
      " [20] invoke_in_world\n",
      "    @ .\\essentials.jl:1086 [inlined]\n",
      " [21] require(into::Module, mod::Symbol)\n",
      "    @ Base .\\loading.jl:2260\n",
      " [22] eval\n",
      "    @ .\\boot.jl:430 [inlined]\n",
      " [23] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base .\\loading.jl:2734\n",
      " [24] #invokelatest#2\n",
      "    @ .\\essentials.jl:1055 [inlined]\n",
      " [25] invokelatest\n",
      "    @ .\\essentials.jl:1052 [inlined]\n",
      " [26] (::VSCodeServer.var\"#217#218\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:24\n",
      " [27] withpath(f::VSCodeServer.var\"#217#218\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\VSCodeServer\\src\\repl.jl:276\n",
      " [28] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}, params::VSCodeServer.NotebookRunCellArguments, token::VSCodeServer.CancellationTokens.CancellationToken)\n",
      "    @ VSCodeServer c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:13\n",
      " [29] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint, VSCodeServer.JSON.Serializations.StandardSerialization}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::VSCodeServer.JSONRPC.Request)\n",
      "    @ VSCodeServer.JSONRPC c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\JSONRPC\\src\\typed.jl:68\n",
      " [30] serve_notebook(pipename::String, debugger_pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; error_handler::var\"#5#10\"{String})\n",
      "    @ VSCodeServer c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\packages\\VSCodeServer\\src\\serve_notebook.jl:147\n",
      " [31] top-level scope\n",
      "    @ c:\\Users\\User\\.cursor\\extensions\\julialang.language-julia-1.149.2\\scripts\\notebook\\notebook.jl:35"
     ]
    }
   ],
   "source": [
    "using Flux, DLProteinFormats, RandomFeatureMaps, StatsBase, Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91mERROR: \u001b[39mLoadError: UndefVarError: `Flux` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "in expression starting at c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\RoPE.jl:25\n",
      "in expression starting at c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\RoPE.jl:25\n",
      "\u001b[91mERROR: \u001b[39mUndefVarError: `Attention` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "\u001b[90m   @\u001b[39m \u001b[90mc:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\\u001b[39m\u001b[90m\u001b[4mGQAttention.jl:3\u001b[24m\u001b[39m\n",
      "in expression starting at c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\GQAttention.jl:3\n"
     ]
    }
   ],
   "source": [
    "includet(\"./RoPE.jl\")\n",
    "includet(\"./GQAttention.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `DLProteinFormats` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `DLProteinFormats` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W2sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "dat = DLProteinFormats.load(PDBSimpleFlat500);\n",
    "\n",
    "L = 30\n",
    "train_inds = findall(dat.len .> L)\n",
    " \n",
    "function random_batch(dat, L, B, filt_inds)\n",
    "    locs = zeros(Float32, 3, L, B)\n",
    "    inds = sample(filt_inds, B, replace=false)\n",
    "    AAs = zeros(Int, L, B)\n",
    "    for (i,ind) in enumerate(inds)\n",
    "        l_range = rand(1:dat[ind].len - L + 1)\n",
    "        locs[:, :, i] = dat[ind].locs[:, 1, l_range:l_range+L-1]\n",
    "        AAs[:, i] = dat[ind].AAs[l_range:l_range+L-1]\n",
    "    end\n",
    "    return (;locs, AAs = Flux.onehotbatch(AAs, 1:20))\n",
    "end\n",
    "\n",
    "batch = random_batch(dat, L, 10, train_inds);\n",
    " \n",
    "struct Toy0{L}\n",
    "    layers::L\n",
    "end\n",
    "Flux.@layer Toy0\n",
    "function Toy0()\n",
    "    layers = (;\n",
    "        AA_decoder = Dense(3 => 20, bias=false),\n",
    "    )\n",
    "    return Toy0(layers)\n",
    "end\n",
    "function (m::Toy0)(locs)\n",
    "    l = m.layers\n",
    "    aa_logits = l.AA_decoder(locs)\n",
    "    return aa_logits\n",
    "end\n",
    " \n",
    "struct Toy1{L}\n",
    "    layers::L\n",
    "end\n",
    "Flux.@layer Toy1\n",
    "function Toy1(dim, depth)\n",
    "    layers = (;\n",
    "        loc_encoder = Dense(3 => dim, bias=false),\n",
    "        transformers = [Onion.TransformerBlock(dim, 8, MultiDimRoPE(Int(dim/8), 3)) for _ in 1:depth],\n",
    "        AA_decoder = Dense(dim => 20, bias=false),\n",
    "    )\n",
    "    return Toy1(layers)\n",
    "end\n",
    "function (m::Toy1)(locs)\n",
    "    l = m.layers\n",
    "    x = l.loc_encoder(locs)\n",
    "    for transformerblock in l.transformers\n",
    "        x = transformerblock(x, 0, nothing, locs)\n",
    "        #locs = updatelocs(x, locs)\n",
    "    end\n",
    "    aa_logits = l.AA_decoder(x)\n",
    "    return aa_logits\n",
    "end\n",
    " \n",
    "struct Toy2{L}\n",
    "    layers::L\n",
    "end\n",
    "Flux.@layer Toy2\n",
    "function Toy2(dim, depth)\n",
    "    layers = (;\n",
    "        loc_rff = RandomFourierFeatures(3 => 64, 0.1f0),\n",
    "        loc_encoder = Dense(64 => dim, bias=false),\n",
    "        transformers = [Onion.TransformerBlock(dim, 8) for _ in 1:depth],\n",
    "        AA_decoder = Dense(dim => 20, bias=false),\n",
    "    )\n",
    "    return Toy2(layers)\n",
    "end\n",
    "function (m::Toy2)(locs)\n",
    "    l = m.layers\n",
    "    x = l.loc_encoder(l.loc_rff(locs))\n",
    "    for layer in l.transformers\n",
    "        x = layer(x, 0, nothing)\n",
    "    end\n",
    "    aa_logits = l.AA_decoder(x)\n",
    "    return aa_logits\n",
    "end\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Toy1` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Toy1` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W3sZmlsZQ==.jl:2"
     ]
    }
   ],
   "source": [
    "#model = Toy0()\n",
    "model = Toy1(64, 4)\n",
    "#model = Toy2(64, 4)\n",
    "opt_state = Flux.setup(AdamW(eta = 0.001), model)\n",
    " \n",
    "losses = Float32[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `model` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `model` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W4sZmlsZQ==.jl:1"
     ]
    }
   ],
   "source": [
    "model.layers.transformers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `random_batch` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `random_batch` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\User\\Desktop\\SoFo\\code\\SoFo-2025-Translation-Equivariant-Transformer\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:4"
     ]
    }
   ],
   "source": [
    "for epoch in 1:20 # 1:100\n",
    "    tot_loss = 0f0\n",
    "    for i in 1:1_000 # 1:10_000\n",
    "        batch = random_batch(dat, L, 10, train_inds);\n",
    "        l, grad = Flux.withgradient(model) do m\n",
    "            aalogits = m(batch.locs)\n",
    "            Flux.logitcrossentropy(aalogits, batch.AAs)\n",
    "        end\n",
    "        Flux.update!(opt_state, model, grad[1])\n",
    "        tot_loss += l\n",
    "        if mod(i, 50) == 0\n",
    "            println(epoch, \" \", i, \" \", tot_loss/50)\n",
    "            push!(losses, tot_loss/50)\n",
    "            tot_loss = 0f0\n",
    "        end\n",
    "        (mod(i, 500) == 0) && savefig(plot(losses), \"losses_toy_MultiDimRoPE.pdf\")\n",
    "    end\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
