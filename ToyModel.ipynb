{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\User\\.julia\\environments\\v1.11\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\User\\.julia\\environments\\v1.11\\Manifest.toml`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(::CPUDevice) (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Install everything, including CUDA, and load packages:\n",
    "using Flux, Statistics, ProgressMeter\n",
    "using CUDA  # optional\n",
    "device = gpu_device()  # function to move data and model to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:04\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate some data for the XOR problem: vectors of length 2, as columns of a matrix:\n",
    "noisy = rand(Float32, 2, 1000)                                    # 2×1000 Matrix{Float32}\n",
    "truth = [xor(col[1]>0.5, col[2]>0.5) for col in eachcol(noisy)]   # 1000-element Vector{Bool}\n",
    "\n",
    "# Define our model, a multi-layer perceptron with one hidden layer of size 3:\n",
    "model = Chain(\n",
    "    Dense(2 => 3, tanh),      # activation function inside layer\n",
    "    BatchNorm(3),\n",
    "    Dense(3 => 2)) |> device  # move model to GPU, if one is available\n",
    "\n",
    "# The model encapsulates parameters, randomly initialised. Its initial output is:\n",
    "out1 = model(noisy |> device)    # 2×1000 Matrix{Float32}, or CuArray{Float32}\n",
    "probs1 = softmax(out1) |> cpu    # normalise to get probabilities (and move off GPU)\n",
    "\n",
    "# To train the model, we use batches of 64 samples, and one-hot encoding:\n",
    "target = Flux.onehotbatch(truth, [true, false])                   # 2×1000 OneHotMatrix\n",
    "loader = Flux.DataLoader((noisy, target), batchsize=64, shuffle=true);\n",
    "\n",
    "opt_state = Flux.setup(Flux.Adam(0.01), model)  # will store optimiser momentum, etc.\n",
    "\n",
    "# Training loop, using the whole data set 1000 times:\n",
    "losses = []\n",
    "@showprogress for epoch in 1:1_000\n",
    "    for xy_cpu in loader\n",
    "        # Unpack batch of data, and move to GPU:\n",
    "        x, y = xy_cpu |> device\n",
    "        loss, grads = Flux.withgradient(model) do m\n",
    "            # Evaluate model and loss inside gradient context:\n",
    "            y_hat = m(x)\n",
    "            Flux.logitcrossentropy(y_hat, y)\n",
    "        end\n",
    "        Flux.update!(opt_state, model, grads[1])\n",
    "        push!(losses, loss)  # logging, outside gradient context\n",
    "    end\n",
    "end\n",
    "\n",
    "opt_state # parameters, momenta and output have all changed\n",
    "\n",
    "out2 = model(noisy |> device)         # first row is prob. of true, second row p(false)\n",
    "probs2 = softmax(out2) |> cpu         # normalise to get probabilities\n",
    "mean((probs2[1,:] .> 0.5) .== truth)  # accuracy 94% so far!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
